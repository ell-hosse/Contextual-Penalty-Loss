{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-RP6kaO157L",
        "outputId": "648875a6-b292-4fa4-96e1-8836191815b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EfgZKET1_Oy",
        "outputId": "434d5491-a74c-472a-96c9-9f6ab3b3a401"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Contextual-Penalty-Loss' already exists and is not an empty directory.\n",
            "/content/Contextual-Penalty-Loss\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ell-hosse/Contextual-Penalty-Loss.git\n",
        "%cd Contextual-Penalty-Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwBGRcHRAGr2",
        "outputId": "e5550a43-2819-4676-c21c-87f8c5419359"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "# If your CPL repo is on GitHub, first pip install it here (uncomment & edit):\n",
        "# !pip install -U pip\n",
        "# !pip install git+https://github.com/<you>/<contextual-penalty-loss>.git\n",
        "\n",
        "import os, math, json\n",
        "from pathlib import Path\n",
        "from typing import Tuple, Dict, List\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# ==== Paths (edit to your folders) ====\n",
        "train_images_dir = \"/content/drive/MyDrive/SemantiCAM/bdd100k_images_10k/10k/train\"\n",
        "train_masks_dir = \"/content/drive/MyDrive/SemantiCAM/bdd100k_seg_maps/color_labels/train\"\n",
        "val_images_dir = \"/content/drive/MyDrive/SemantiCAM/bdd100k_images_10k/10k/val\"\n",
        "val_masks_dir = \"/content/drive/MyDrive/SemantiCAM/bdd100k_seg_maps/color_labels/val\"\n",
        "\n",
        "# ==== Hyperparams ====\n",
        "IMAGE_SIZE = 512\n",
        "BATCH_SIZE = 128\n",
        "WORKERS = 4\n",
        "EPOCHS = 30\n",
        "BASE_CH = 64\n",
        "LR = 3e-4\n",
        "USE_AMP = True\n",
        "\n",
        "# CPL weights\n",
        "W_CPL = 1.0\n",
        "W_CE = 0.2  # small CE blend helps early stability\n",
        "\n",
        "OUT_DIR = \"/content/drive/MyDrive/CPLoss/saved_model/\"\n",
        "\n",
        "IGNORE_INDEX = 255\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmSsmoMUAIBw",
        "outputId": "f2afa3ab-c94c-48c5-abac-25945a320e4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity matrix built with context. Shape: (19, 19)\n"
          ]
        }
      ],
      "source": [
        "# BDD100K classes\n",
        "BDD_CLASSES = [\n",
        "    \"road\",\"sidewalk\",\"building\",\"wall\",\"fence\",\"pole\",\"traffic light\",\"traffic sign\",\n",
        "    \"vegetation\",\"terrain\",\"sky\",\"person\",\"rider\",\"car\",\"truck\",\"bus\",\"train\",\"motorcycle\",\"bicycle\"\n",
        "]\n",
        "NUM_CLASSES = len(BDD_CLASSES)\n",
        "\n",
        "# Common color palette for color-label masks\n",
        "BDD_COLORS = [\n",
        "    (128,64,128), (244, 35,232), ( 70, 70, 70), (102,102,156), (190,153,153),\n",
        "    (153,153,153), (250,170, 30), (220,220,  0), (107,142, 35), (152,251,152),\n",
        "    ( 70,130,180), (220, 20, 60), (255,  0,  0), (  0,  0,142), (  0,  0, 70),\n",
        "    (  0, 60,100), (  0, 80,100), (  0,  0,230), (119, 11, 32),\n",
        "]\n",
        "COLOR2ID = {c:i for i,c in enumerate(BDD_COLORS)}\n",
        "\n",
        "# --- Contextual groups to encode similarity (domain knowledge) ---\n",
        "GROUPS = {\n",
        "    \"ground\": [\"road\",\"sidewalk\",\"terrain\"],\n",
        "    \"construction\": [\"building\",\"wall\",\"fence\"],\n",
        "    \"object\": [\"pole\",\"traffic light\",\"traffic sign\"],\n",
        "    \"nature\": [\"vegetation\",\"terrain\"],  # overlaps with ground by nature; that's OK\n",
        "    \"sky\": [\"sky\"],\n",
        "    \"human\": [\"person\",\"rider\"],\n",
        "    \"vehicle\": [\"car\",\"truck\",\"bus\",\"train\",\"motorcycle\",\"bicycle\"]\n",
        "}\n",
        "# Cross-group relatedness (handcrafted priors)\n",
        "RELATED = {\n",
        "    (\"ground\",\"construction\"): 0.45,\n",
        "    (\"ground\",\"vehicle\"): 0.35,\n",
        "    (\"human\",\"vehicle\"): 0.30,\n",
        "    (\"construction\",\"object\"): 0.40,\n",
        "    (\"nature\",\"ground\"): 0.40,\n",
        "}\n",
        "WITHIN = 0.82 # within-group similarity\n",
        "LOW = 0.08 # unrelated baseline\n",
        "\n",
        "def build_similarity_matrix(classes: List[str]) -> torch.Tensor:\n",
        "    idx = {c:i for i,c in enumerate(classes)}\n",
        "    C = len(classes)\n",
        "    S = torch.full((C,C), LOW, dtype=torch.float32)\n",
        "    # diag\n",
        "    for i in range(C):\n",
        "        S[i,i] = 1.0\n",
        "    # within-group\n",
        "    for members in GROUPS.values():\n",
        "        ids = [idx[c] for c in members if c in idx]\n",
        "        for i in ids:\n",
        "            for j in ids:\n",
        "                if i != j:\n",
        "                    S[i,j] = max(float(S[i,j]), WITHIN)\n",
        "    # cross-group relatedness\n",
        "    for (g1,g2), val in RELATED.items():\n",
        "        ids1 = [idx[c] for c in GROUPS[g1] if c in idx]\n",
        "        ids2 = [idx[c] for c in GROUPS[g2] if c in idx]\n",
        "        for i in ids1:\n",
        "            for j in ids2:\n",
        "                S[i,j] = max(float(S[i,j]), val)\n",
        "                S[j,i] = max(float(S[j,i]), val)\n",
        "    # ensure symmetry\n",
        "    S = 0.5*(S + S.T)\n",
        "    return S\n",
        "\n",
        "S_matrix = build_similarity_matrix(BDD_CLASSES).to(device)\n",
        "print(\"Similarity matrix built with context. Shape:\", tuple(S_matrix.shape))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ik9CwnG2AODo",
        "outputId": "18b63791-526c-4aac-da90-93600b1c6b9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imported CPLoss from installed package.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Contextual-Penalty-Loss/cploss/loss.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @torch.cuda.amp.autocast(enabled=False)\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from cploss import CPLoss  # your repo\n",
        "    print(\"Imported CPLoss from installed package.\")\n",
        "except Exception as e:\n",
        "    print(\"[WARN] Could not import cploss; using minimal inline CPL.\")\n",
        "    class CPLoss(nn.Module):\n",
        "        def __init__(self, S: torch.Tensor, w_cpl=1.0, w_ce=0.2,\n",
        "                     ignore_index=255, reduction='mean', from_logits=True, eps=1e-8):\n",
        "            super().__init__()\n",
        "            self.register_buffer(\"S\", S.clamp(0,1))\n",
        "            C = S.size(0)\n",
        "            eye = torch.eye(C, device=S.device, dtype=S.dtype)\n",
        "            self.S = torch.maximum(self.S, eye)\n",
        "            self.D = (1.0 - self.S)\n",
        "            self.w_cpl, self.w_ce = float(w_cpl), float(w_ce)\n",
        "            self.ignore_index, self.reduction = ignore_index, reduction\n",
        "            self.from_logits, self.eps = from_logits, eps\n",
        "            self.ce = nn.CrossEntropyLoss(ignore_index=ignore_index, reduction=reduction)\n",
        "\n",
        "        def forward(self, logits, target):\n",
        "            if self.from_logits:\n",
        "                probs = F.softmax(logits.float(), dim=1)\n",
        "            else:\n",
        "                probs = (logits.float() + self.eps) / (logits.float().sum(dim=1, keepdim=True) + self.eps)\n",
        "\n",
        "            N, C, H, W = probs.shape\n",
        "            probs_flat = probs.permute(0,2,3,1).reshape(-1, C)\n",
        "            target_flat = target.view(-1).to(logits.device)\n",
        "            valid = (target_flat != self.ignore_index)\n",
        "\n",
        "            if valid.any():\n",
        "                t_idx = target_flat[valid]\n",
        "                D_y = self.D.to(logits.device)[t_idx] # (M,C)\n",
        "                p_val = probs_flat[valid] # (M,C)\n",
        "                cpl = (p_val * D_y).sum(dim=1).mean()\n",
        "            else:\n",
        "                cpl = logits.sum() * 0.0 # keeps graph/device\n",
        "\n",
        "            out = self.w_cpl * cpl\n",
        "            if self.w_ce > 0:\n",
        "                out = out + self.w_ce * self.ce(logits, target)\n",
        "            return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kjIDVom5lJo",
        "outputId": "f2b61e45-e7a9-49ed-e220-528f16ee86f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 7000\n",
            "Sample shapes: torch.Size([3, 512, 512]) torch.Size([512, 512]) unique labels (sample): tensor([ 0,  2,  4,  5,  6,  7,  8, 10, 11, 13])\n"
          ]
        }
      ],
      "source": [
        "class BDD10KSeg(Dataset):\n",
        "    def __init__(self, img_dir, mask_dir, size: int = 512):\n",
        "        self.img_paths = sorted([str(p) for p in Path(img_dir).glob(\"*.jpg\")])\n",
        "        self.mask_paths = sorted([str(p) for p in Path(mask_dir).glob(\"*.png\")])\n",
        "        assert len(self.img_paths) == len(self.mask_paths) and len(self.img_paths)>0, \\\n",
        "            \"No data found or count mismatch between images and masks.\"\n",
        "        self.to_tensor = transforms.Compose([\n",
        "            transforms.Resize((size,size), interpolation=transforms.InterpolationMode.BILINEAR),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "        self.resize_mask = transforms.Resize((size,size), interpolation=transforms.InterpolationMode.NEAREST)\n",
        "\n",
        "    def __len__(self): return len(self.img_paths)\n",
        "\n",
        "    def _rgb_mask_to_ids(self, mask_rgb: np.ndarray) -> np.ndarray:\n",
        "        H, W, _ = mask_rgb.shape\n",
        "        ids = np.full((H,W), IGNORE_INDEX, dtype=np.uint8)\n",
        "        mask_flat = mask_rgb.reshape(-1,3)\n",
        "        ids_flat = ids.reshape(-1)\n",
        "        table = np.array(BDD_COLORS, dtype=np.uint8)\n",
        "        for cid, color in enumerate(table):\n",
        "            hits = np.all(mask_flat == color, axis=1)\n",
        "            ids_flat[hits] = cid\n",
        "        return ids\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        img = Image.open(self.img_paths[i]).convert(\"RGB\")\n",
        "        m = Image.open(self.mask_paths[i])\n",
        "        if m.mode == \"P\" or (m.mode == \"L\" and np.array(m).ndim == 2):\n",
        "            mask_np = np.array(self.resize_mask(m), dtype=np.uint8)\n",
        "        else:\n",
        "            m = self.resize_mask(m.convert(\"RGB\"))\n",
        "            mask_np = self._rgb_mask_to_ids(np.array(m, dtype=np.uint8))\n",
        "        img_t = self.to_tensor(img)\n",
        "        mask_t = torch.from_numpy(mask_np).long()\n",
        "        return img_t, mask_t\n",
        "\n",
        "# Quick smoke test (first sample)\n",
        "_dataset_test = BDD10KSeg(train_images_dir, train_masks_dir, size=IMAGE_SIZE)\n",
        "print(\"Train samples:\", len(_dataset_test))\n",
        "x0, y0 = _dataset_test[0]\n",
        "print(\"Sample shapes:\", x0.shape, y0.shape, \"unique labels (sample):\", torch.unique(y0)[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikEl6YEf5owL",
        "outputId": "31bbc427-42b4-4c1d-e08c-638f7c2188e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31.386003"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "    def forward(self, x): return self.block(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_ch=3, num_classes=NUM_CLASSES, base=BASE_CH):\n",
        "        super().__init__()\n",
        "        self.d1 = DoubleConv(in_ch, base)\n",
        "        self.d2 = DoubleConv(base, base*2)\n",
        "        self.d3 = DoubleConv(base*2, base*4)\n",
        "        self.d4 = DoubleConv(base*4, base*8)\n",
        "        self.b  = DoubleConv(base*8, base*16)\n",
        "\n",
        "        self.u4 = DoubleConv(base*16 + base*8, base*8)\n",
        "        self.u3 = DoubleConv(base*8  + base*4, base*4)\n",
        "        self.u2 = DoubleConv(base*4  + base*2, base*2)\n",
        "        self.u1 = DoubleConv(base*2  + base,   base)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.out  = nn.Conv2d(base, num_classes, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        c1 = self.d1(x)\n",
        "        c2 = self.d2(self.pool(c1))\n",
        "        c3 = self.d3(self.pool(c2))\n",
        "        c4 = self.d4(self.pool(c3))\n",
        "        cb = self.b(self.pool(c4))\n",
        "\n",
        "        u4 = F.interpolate(cb, scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
        "        u4 = self.u4(torch.cat([u4, c4], dim=1))\n",
        "        u3 = F.interpolate(u4, scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
        "        u3 = self.u3(torch.cat([u3, c3], dim=1))\n",
        "        u2 = F.interpolate(u3, scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
        "        u2 = self.u2(torch.cat([u2, c2], dim=1))\n",
        "        u1 = F.interpolate(u2, scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
        "        u1 = self.u1(torch.cat([u1, c1], dim=1))\n",
        "        return self.out(u1)\n",
        "\n",
        "model = UNet().to(device)\n",
        "sum(p.numel() for p in model.parameters())/1e6\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sfPgqQUAUZQ",
        "outputId": "20c9cdf9-616c-4019-908c-19aa6a95f6e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaders ready. Batches: 110 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-2333163965.py:19: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n"
          ]
        }
      ],
      "source": [
        "def fast_hist(true, pred, num_classes):\n",
        "    k = (true >= 0) & (true < num_classes)\n",
        "    return torch.bincount(\n",
        "        (true[k] * num_classes + pred[k]).to(torch.int64),\n",
        "        minlength=num_classes**2,\n",
        "    ).reshape(num_classes, num_classes)\n",
        "\n",
        "train_set = BDD10KSeg(train_images_dir, train_masks_dir, size=IMAGE_SIZE)\n",
        "val_set = BDD10KSeg(val_images_dir,   val_masks_dir,   size=IMAGE_SIZE)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          num_workers=WORKERS, pin_memory=True)\n",
        "val_loader = DataLoader(val_set,   batch_size=BATCH_SIZE, shuffle=False,\n",
        "                          num_workers=WORKERS, pin_memory=True)\n",
        "\n",
        "criterion = CPLoss(S=S_matrix, alpha=0.2,\n",
        "                   ignore_index=IGNORE_INDEX, reduction='mean').to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n",
        "\n",
        "print(\"Loaders ready. Batches:\", len(train_loader), len(val_loader))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508,
          "referenced_widgets": [
            "d0c91577659c4dfda3e0e11d08034ac3",
            "1c7efb443e4b4da5bc48f49359d07d24",
            "34a937902a914312916ef6c76c48cb27",
            "d9a35f267ddb477da5bcf5acde801324",
            "eb29f40604854b0bb62722dec5eafefe",
            "bfa872a07b1a4aa7b5a0cb5c79999053",
            "0b410d0e79a944909c8424810d178e27",
            "7586ee3b54474df0acdb2acd768b1dbf",
            "2a733dcdf90f4c6e9a50354ac22837e2",
            "629271f9b05b4259ae84e4adfc2e1671",
            "f78394cadad74e73b7d51ef2b0987953"
          ]
        },
        "id": "pBzXcfEAAYKO",
        "outputId": "c0101c8a-4e65-4dae-9025-005057b18acb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 001/30:   0%|          | 0/110 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0c91577659c4dfda3e0e11d08034ac3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3839100715.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=USE_AMP):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 596.12 MiB is free. Process 89058 has 14.15 GiB memory in use. Of the allocated memory 13.03 GiB is allocated by PyTorch, and 1.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3839100715.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_to_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mUSE_AMP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-809472278.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mc3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mc4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-809472278.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         )\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mUNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             )\n\u001b[0;32m--> 543\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    544\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         )\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 596.12 MiB is free. Process 89058 has 14.15 GiB memory in use. Of the allocated memory 13.03 GiB is allocated by PyTorch, and 1.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "def validate(model, loader):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    hist = torch.zeros(NUM_CLASSES, NUM_CLASSES, dtype=torch.int64)\n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(loader, total=len(loader), desc=\"Validate\", leave=False)\n",
        "        for imgs, masks in pbar:\n",
        "            imgs, masks = imgs.to(device), masks.to(device)\n",
        "            logits = model(imgs)\n",
        "            loss = criterion(logits, masks)\n",
        "            total_loss += float(loss) * imgs.size(0)\n",
        "\n",
        "            preds = logits.argmax(1)\n",
        "            for t, p in zip(masks, preds):\n",
        "                valid = (t != IGNORE_INDEX)\n",
        "                hist += fast_hist(t[valid].view(-1), p[valid].view(-1), NUM_CLASSES).cpu()\n",
        "\n",
        "            pbar.set_postfix({\"batch_loss\": f\"{float(loss):.4f}\"})\n",
        "    # mIoU\n",
        "    hist = hist.numpy()\n",
        "    iu = np.diag(hist) / (hist.sum(1) + hist.sum(0) - np.diag(hist) + 1e-10)\n",
        "    miou = float(np.nanmean(iu))\n",
        "    avg_loss = total_loss / len(loader.dataset)\n",
        "    return avg_loss, miou\n",
        "\n",
        "best_miou = -1.0\n",
        "best_path = Path(OUT_DIR) / \"best_model.pt\"\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    running = 0.0\n",
        "    pbar = tqdm(train_loader, total=len(train_loader), desc=f\"Epoch {epoch:03d}/{EPOCHS}\", leave=True)\n",
        "    for imgs, masks in pbar:\n",
        "        imgs, masks = imgs.to(device), masks.to(device)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(enabled=USE_AMP):\n",
        "            logits = model(imgs)\n",
        "            loss = criterion(logits, masks)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running += float(loss) * imgs.size(0)\n",
        "        pbar.set_postfix({\"batch_loss\": f\"{float(loss):.4f}\"})\n",
        "\n",
        "    train_loss = running / len(train_loader.dataset)\n",
        "    val_loss, val_miou = validate(model, val_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} | train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | mIoU={val_miou:.4f}\")\n",
        "\n",
        "    # Save best by mIoU\n",
        "    if val_miou > best_miou:\n",
        "        best_miou = val_miou\n",
        "        torch.save({\n",
        "            \"epoch\": epoch,\n",
        "            \"state_dict\": model.state_dict(),\n",
        "            \"best_miou\": best_miou,\n",
        "            \"classes\": BDD_CLASSES\n",
        "        }, best_path)\n",
        "        print(f\"New best mIoU {best_miou:.4f}. Saved -> {best_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbzjrehqAhpm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d0c91577659c4dfda3e0e11d08034ac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c7efb443e4b4da5bc48f49359d07d24",
              "IPY_MODEL_34a937902a914312916ef6c76c48cb27",
              "IPY_MODEL_d9a35f267ddb477da5bcf5acde801324"
            ],
            "layout": "IPY_MODEL_eb29f40604854b0bb62722dec5eafefe"
          }
        },
        "1c7efb443e4b4da5bc48f49359d07d24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfa872a07b1a4aa7b5a0cb5c79999053",
            "placeholder": "​",
            "style": "IPY_MODEL_0b410d0e79a944909c8424810d178e27",
            "value": "Epoch 001/30:   0%"
          }
        },
        "34a937902a914312916ef6c76c48cb27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7586ee3b54474df0acdb2acd768b1dbf",
            "max": 110,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a733dcdf90f4c6e9a50354ac22837e2",
            "value": 0
          }
        },
        "d9a35f267ddb477da5bcf5acde801324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_629271f9b05b4259ae84e4adfc2e1671",
            "placeholder": "​",
            "style": "IPY_MODEL_f78394cadad74e73b7d51ef2b0987953",
            "value": " 0/110 [03:06&lt;?, ?it/s]"
          }
        },
        "eb29f40604854b0bb62722dec5eafefe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfa872a07b1a4aa7b5a0cb5c79999053": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b410d0e79a944909c8424810d178e27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7586ee3b54474df0acdb2acd768b1dbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a733dcdf90f4c6e9a50354ac22837e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "629271f9b05b4259ae84e4adfc2e1671": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f78394cadad74e73b7d51ef2b0987953": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}